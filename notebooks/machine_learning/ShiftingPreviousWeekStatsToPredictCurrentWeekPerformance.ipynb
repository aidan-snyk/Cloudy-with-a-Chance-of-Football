{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shifting Previous Week Stats to Predict Current Week Performance\n",
    "Author: Aidan O'Connor   \n",
    "Date: 15 June 2021   \n",
    "\n",
    "In this notebook, I'll take previous week stats and shift them to current week predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas for data manipulation and sqlite3 for stored data access\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a database connection\n",
    "conn = sqlite3.connect('../../fixtures/database/cloudy_with_a_chance_of_football.db')\n",
    "cursorObj = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in stats data grouped and ordered by PlayerID and week_id\n",
    "stats = pd.read_sql_query(\n",
    "    \"\"\"\n",
    "    SELECT PlayerID,week_id\n",
    "    from stats_regular\n",
    "    GROUP BY PlayerID, week_id\n",
    "    ORDER BY PlayerID, week_id;\n",
    "    \"\"\"\n",
    "    ,conn\n",
    ").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create year and week columns to help order the data, then sort by both\n",
    "stats['year'] = [n[0:4] for n in stats['week_id']]\n",
    "stats['week'] = [int(n[-1]) if len(n) == 6 else int(n[-2:]) for n in stats['week_id']]\n",
    "stats = stats.sort_values(by = ['PlayerID','week'])\n",
    "\n",
    "# Create 2 subordinate dataframes to ensure no data overlap\n",
    "stats_2019 = stats[['PlayerID','week']][stats['year'] == '2019']\n",
    "stats_2020 = stats[['PlayerID','week']][stats['year'] == '2020']\n",
    "\n",
    "# Make a list of dataframes to apply this next function to\n",
    "frames_to_shift = [stats_2019, stats_2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_shifter(dataframe):\n",
    "    \"\"\"\n",
    "    Shifts previous week stats to help predict current week performance\n",
    "    Different from pandas shift, takes into account unique player ID\n",
    "    Input: dataframe with PlayerID and week columns\n",
    "    \"\"\"\n",
    "    new_week_id_list = []\n",
    "    \n",
    "    for n in range(0,len(dataframe) - 1):\n",
    "        if dataframe['PlayerID'].iloc[n] == dataframe['PlayerID'].iloc[n+1]:\n",
    "            new_week_id_list.append(dataframe['week'].iloc[n+1])\n",
    "        else:\n",
    "            new_week_id_list.append(0)\n",
    "            \n",
    "    new_week_id_list.append(0)\n",
    "    dataframe['new_week_id_list'] = new_week_id_list\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the stat_shifter function to the dataframes\n",
    "for n in frames_to_shift:\n",
    "    n = stat_shifter(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a week_id and new_week_id column for each subordinate dataframe\n",
    "stats_2019['week_id'] = '2019_' + stats_2019['week'].astype(str)\n",
    "stats_2019['new_week_id'] = '2019_' + stats_2019['new_week_id_list'].astype(str)\n",
    "stats_2020['week_id'] = '2020_' + stats_2020['week'].astype(str)\n",
    "stats_2020['new_week_id'] = '2020_' + stats_2020['new_week_id_list'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append 2020 dataframe to 2019 dataframe\n",
    "merged_stats = stats_2019.append(stats_2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in stats data\n",
    "df = pd.read_csv('../../fixtures/cleaned_data/fantasyPlayerScores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the shifted stats columns and the overall stats table, dropping 2018\n",
    "# from the merged dataframe\n",
    "merged_df = pd.merge(\n",
    "    df,\n",
    "    merged_stats.drop(['week','new_week_id_list'], axis = 'columns'),\n",
    "    how = 'left',\n",
    "    left_on = ['PlayerID','week_id'],\n",
    "    right_on = ['PlayerID','week_id']\n",
    ")\n",
    "\n",
    "merged_df = merged_df[merged_df['Season'] != 2018].drop('week_id', axis = 'columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x7fe01c8601f0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the old stats table...\n",
    "cursorObj.execute(\"DROP TABLE stats_regular\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('positions',), ('player_dob',), ('players',), ('player_team',), ('player_age',), ('team_home_time_zone',), ('injury_status',), ('days_since_last_game',), ('weather',), ('hours_displaced',), ('stats_red_zone',), ('elevation_and_conference',), ('performance_target',), ('stats_regular',)]\n"
     ]
    }
   ],
   "source": [
    "# ...and add in the new one, then check to make sure it stuck\n",
    "merged_df.to_sql('stats_regular',\n",
    "                con = conn,\n",
    "                index = False,\n",
    "                if_exists = 'append'\n",
    ")\n",
    "\n",
    "cursorObj.execute('SELECT name from sqlite_master where type = \"table\"')\n",
    "print(cursorObj.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the database connection\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
